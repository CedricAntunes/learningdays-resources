---
title: "Estimando Estimandos con Estimadores"
author: "Fill In Your Name"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  beamer_presentation:
    keep_tex: yes
    slide_level: 2
    toc: yes
  revealjs::revealjs_presentation:
    center: no
    fig_caption: yes
    highlight: pygments
    pandoc_args: --toc
    reveal_options:
      chalkboard:
        theme: whiteboard
        toggleNotesButton: no
      previewLinks: yes
      slideNumber: yes
    reveal_plugins:
    - notes
    - search
    - chalkboard
    self_contained: no
    smart: no
    theme: default
    transition: fade
bibliography: ../learningdays-book.bib
header-includes: |
   \setbeamertemplate{footline}{\begin{beamercolorbox}{section in head/foot}
   \includegraphics[height=.5cm]{../Images/egap-logo.png} \hfill
   \insertframenumber/\inserttotalframenumber \end{beamercolorbox}}
   \usepackage{makecell}
   \usepackage{tikz}
   \usepackage{tikz-cd}
   \usetikzlibrary{arrows,automata,positioning,trees,babel}
   \usepackage{textpos}
   \usepackage{booktabs,multirow}
link-citations: yes
colorlinks: yes
biblio-style: apalike
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
source("rmd_setup.R")
# Load all the libraries we need
library(here)
library(tidyverse)
library(kableExtra)
library(DeclareDesign)
library(estimatr)
library(styler)


```

# Puntos Clave

## Puntos clave para la estimación I

  -  Un efecto causal, $\tau_i$, es una comparación de salidas potenciales no observadas para cada unidad  $i$, por ejemplo:  $\tau_{i} = Y_{i}(T_{i}=1) -  Y_{i}(T_{i}=0)$ or  $\tau_{i} = \frac{Y_{i}(T_{i}=1)}{ Y_{i}(T_{i}=0)}$.

  - Para aprender sobre $\tau_{i}$, podemos tratar a  $\tau_{i}$ como un **estimando** o una cantidad objetivo a ser estimada (discutido acá),  o como una cantidad objetivo sobre la cual se plantearán hipótesis (sesión de pruebas hipótesis).

  - Hay muchas personas que se enfoncan en el **efecto promedio del tratamiento**  (average treatment effect, ATE), $\bar{\tau}=\sum_{i=1}^n\tau_{i}$, en parte, porque permite una  **estimación** fácil.

## Puntos clave para la estimación II

- La clave para la estimación en la inferencia causal es elegir un estimando que permita aprender sobre alguna pregunta teórica o de políticas. Para esto, el ATE es una opción, pero otros estimandos comunes también incluyen el ITT, LATE/CACE, ATT o ATE para algún subgrupo (o incluso una diferencia de un efecto causal entre grupos).

  - Un **estimador** es una receta para hacer una estimación sobre el valor de un estimando. Por ejemplo, la diferencia de medias observadas para $m$ unidades tratadas es un estimador de $\bar{\tau}$:
   $\hat{\bar{\tau}} = \frac{\sum_{i=1}^n (T_i Y_i)}{m} - \frac{\sum_{i=1}^n ( ( 1 - T_i)Y_i)}{(n-m)}$.

## Puntos clave para la estimación III

- El **error estándar** de un estimador de un experimento aleatorio resume cómo variarían las estimaciones si se repitiera el experimento.

 - Usamos el **error estándar** para producir **intervalos de confianza** y
   **valores p**:  comenzamos con un estimador y terminamos con una prueba de hipótesis.

  - Diferentes aleatorizaciones producirán diferentes valores del mismo estimador que busca estimar el mismo estimando. Un **error estándar** resume esta variabilidad en un estimador.

  - Un  **intervalo de confianza** del $100 (1- \ alpha)$% es una colección de hipótesis que no se pueden rechazar al nivel $\alpha$. Es común reportar intervalos de confianza que contienen hipótesis sobre los valores de nuestro estimando y usamos nuestro estimador como una estadística de prueba.

## Puntos clave sobre la estimación IV

 - Los estimadores deben:
 
      - evitar errores sistemáticos al estimar el estimando (ser insesgado);
   
      - varíar poco en las estimaciones de un experimento a otro.
   experimento (ser preciso o eficiente); y
   
      - idealmente converger al estimando a medida que se utiliza más información (ser consistente).

## Puntos clave sobre la estimación V

 - **Analizar mientras se aleatoriza** en el contexto de la estimación significa que (1) nuestros errores estándar deben medir la variabilidad de la aleatorización y (2) nuestros estimadores deben apuntar a estimaciones definidas en términos de salidas potenciales.

 - No **controlamos** por las covariables cuando analizamos datos de experimentos aleatorios. Pero las covariables pueden hacer que nuestra estimación sea más **precisa**. Esto se denomina **ajuste de covarianza**  (o ajuste de covariables). Tenga en cuenta que es diferente controlar  en estudios observacionales a hacer **ajuste de covarianza** en experimentos aleatorios.

# Recapitulación

## Recapitulación: efectos causales

Recapitulación: La inferencia causal se trata de una comparación de salidas potenciales fijas no observados.

Por ejemplo:

  - la salida potencial, o posible, de la unidad $i$ cuando se asigna al
    tratamiento, $T_i = 1$ es $Y_{i} (T_{i} = 1)$.
  - la salida potencial, o posible, de la unidad $i$ cuando se asigna al
    control, $T_i = 0$ es $Y_{i}(T_ {i} = 0)$.

La asignación al tratamiento, $T_i $, tiene un efecto causal para la unidad $i$ al que llamamos $\tau_i$, si
$Y_{i}(T_{i} = 1) - Y_{i}(T_ {i} = 0) \ne 0$ o $Y_{i}(T_ {i} = 1) \ne Y_{i}(T_ {i} = 0)$.

# Estimandos y estimadores y promedios

## ¿Cómo podemos aprender sobre los efectos causales utilizando los datos observados?

1. Recuerde: podemos **probar hipótesis** sobre las dos salidas potenciales $\{Y_{i}(T_ {i} = 1), Y_{i} (T_{i} = 0)\}$.
 
 2. Podemos **definir estimandos** en términos de $\{Y_ {i} (T_ {i} = 1), Y_ {i} (T_ {i} = 0) \} $ o $\tau_i$, **desarrollar estimadores** para esos estimandos,
    y luego calcular los valores y los errores estándar para esos estimadores.

## Un estimando y estimador común: el efecto del tratamiento promedio y la diferencia de medias

Digamos que estamos interesados en el ATE, o $\bar {\tau} = \sum_{i = 1}^n \ tau_{i}$. ¿Qué determina a un buen estimador?

Dos candidatos:

 1. La diferencia de medias: $\hat{\bar{\tau}} = \frac{\sum_{i = 1}^n(T_i Y_i)}{m} - \frac{\sum_{i = 1}^n((1 - T_i) Y_i)}{n-m}$.
    
 2. Una diferencia de medias después de recodificar el máximo de las observaciones $Y_i$ (una
    una especie de media "truncada" (winsorized), con lo que se busca evitar que los valores extremos ejerzan demasiada
    influencia sobre nuestro estimador; se usa para aumentar la *precisión*).

¿Cómo sabríamos cuál estimador es mejor para un diseño de investigación en particular?

¡Simulemos!

## Paso 1 de la simulación: generar datos con un ATE conocido

Tenga en cuenta que necesitamos *conocer* las salidas potenciales y la
asignación al tratamiento para saber si nuestro estimador propuesto está haciendo un buen trabajo.
```{r echo=FALSE}

## Primero, generar datos
##  y0 es la salida potencial bajo el control
N <- 10
y0 <- c(0, 0, 0, 1, 1, 3, 4, 5, 190, 200)
## Para cada unidad el efecto del tratamiento es intrínseco
tau <- c(10, 30, 200, 90, 10, 20, 30, 40, 90, 20)
## y1 es la salida potencial bajo el tratamiento
y1 <- y0 + tau
## Z es la asignación al tratamiento 
## (Tenga en cuenta que estamos usando Z en vez T)
set.seed(12345)
block <- c("a","a","a","a","a","a","b","b","b","b")
Z <- c(0,0,0,0,1,1,0,0,1,1)
## Y es la salida potencial realizada
Y <- Z * y1 + (1 - Z) * y0
## Los datos
dat <- data.frame(Z = Z, y0 = y0, y1 = y1, tau = tau, b=block,Y=Y)
## dat <- dat[,c("Z","y0","y1")]
```

\begin{center}
```{r}
kableExtra::kable(dat[,c("Z","y0","y1")])
```
\end{center}

```{r ate, echo=FALSE, results="markup", message=TRUE}
ATE <- with(dat, mean(y1 - y0))
message("El ATE real es ", ATE)
```

En la realidad sólo podemos observar una salida potencial.

Tenga en cuenta que cada unidad tiene su propio efecto bajo el tratamiento.

## Primero: generar datos artificiales

La tabla en la diapositiva anterior fue generada en R con:


```{r echo=TRUE}
# Tenemos 10 unidades
N <- 10
#  y0 es la salida potencial bajo el control
y0 <- c(0, 0, 0, 1, 1, 3, 4, 5, 190, 200)
# Para cada unidad el efecto del tratamiento es intrínseco
tau <- c(10, 30, 200, 90, 10, 20, 30, 40, 90, 20)
## y1 es la salida potencial bajo el tratamiento
y1 <- y0 + tau
# Dos bloques: a y b
block <- c("a","a","a","a","a","a","b","b","b","b")
# Z  es la asignación al tratamiento 
# (Z en vez de  T en el código)
Z <- c(0,0,0,0,1,1,0,0,1,1)
# Y es la salida potencial observado
Y <- Z * y1 + (1 - Z) * y0
# Los datos
dat <- data.frame(Z = Z, y0 = y0, y1 = y1, tau = tau, b=block,Y=Y)
set.seed(12345)
```


## Usando DeclareDesign 

En DeclareDesign se pueden representar diseños de investigación en apenas unos pocos pasos como se muestra a continuación:

```{r dd1, echo=TRUE}
# Seleccione solamente las salidas potenciales bajo
# el tratamiento y bajo el control de nuestros datos artificiales
small_dat <- dat[, c("y0", "y1")]

# DeclareDesign le pide que primero declare a su población
pop <- declare_population(small_dat)

# 5 unidades asignadas al tratamiento; 
# Por defecto DeclareDesign utiliza asignación
# aleatoria simple con probabilidad de 0.5
trt_assign <- declare_assignment(m = 5, legacy = TRUE) 

# El valor realizado de Y es y1 si Z=1y y0 si Z=0
pot_out <- declare_potential_outcomes(Y ~ Z * y1 + (1 - Z) * y0)

# Especificar variable de intenterés y asignación al tratamiento
reveal <- declare_reveal(Y, Z) 

# El objeto de diseño de investigación básico incluye incluye estos cuatro objetos
base_design <- pop + trt_assign + pot_out + reveal 
```

## Usando DeclareDesign: creación de datos artificiales

DeclareDesign renombra `y0` and `y1` por defecto como `Y_Z_0` y `Y_Z_1`:

```{r echo=TRUE}
## Una simulación es una asignación aleatoria al tratamiento 
sim_dat1 <- draw_data(base_design)

## Data simulada (sólo las primeras 6 lineas)
head(sim_dat1)
```

## Utilizando DeclareDesign: definir estimandos y estimadores

El siguiente código no produce ninguna salida. Solo define las funciones, estimadores y estimando.

```{r dd2, echo=TRUE}
## The estimand
estimandATE <- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0))

## The first estimator is difference-in-means
diff_means <- declare_estimator(Y ~ Z, inquiry = estimandATE, 
  model = lm_robust, se_type = "classical", label = "Diff-Means/OLS")
```

## Utilizando DeclareDesign: definir estimandos y estimadores
```{r dd2a, echo=TRUE}
## El segundo estimador es   top-coded difference-in-means
diff_means_topcoded_fn <- function(data) {
  data$rankY <- rank(data$Y)
  ## Codifica el valor máximo de Y como el segundo valor máximo de Y
  data$newY <- with(data,
    ifelse(rankY == max(rankY), Y[rankY == (max(rankY) - 1)], Y))
  obj <- lm_robust(newY ~ Z, data = data, se_type = "classical")
  res <- tidy(obj) %>% filter(term == "Z")
  return(res)
}
diff_means_topcoded <- declare_estimator(
  handler = label_estimator(diff_means_topcoded_fn),
  inquiry = estimandATE, label = "Top-coded Diff Means"
)
```

## Utilizando DeclareDesign: definir estimandos y estimadores

A continuación presentamos cómo funcionan los estimadores en DD utilizando datos simulados.

```{r dd3, echo=TRUE}
## Demuestra que el estimando funciona
estimandATE(sim_dat1)

## Demuestra que que los estimador estiman

## Estimador (diferencia de medias)
diff_means(sim_dat1)[-c(1,2,10,11)]

## Estimador 2 (diferencia de medias acotada )
diff_means_topcoded(sim_dat1)[-c(1,2,10,11)]
```


## Luego simular una aleatorización 

Recordemos cuál es el ATE real:
  
```{r trueATE, echo=TRUE}
trueATE <- with(sim_dat1, mean(y1 - y0))
with(sim_dat1, mean(Y_Z_1 - Y_Z_0))
```

En un experimento (una simulación de los datos)
estos son los estimados simples:
  
```{r echo=TRUE}
## Dos formas de calcular el 
# estimador de las diferencia de medias

est_diff_means_1 <- with(sim_dat1, mean(Y[Z == 1]) - mean(Y[Z == 0]))
est_diff_means_2 <- coef(lm_robust(Y ~ Z, data = sim_dat1,
        se = "classical"))[["Z"]]
c(est_diff_means_1,est_diff_means_2)
```

## Luego simular una aleatorización 

En un experimento (una simulación de los datos) estos son los estimados después de truncar por arriba:

```{r echo=TRUE}
## Dos formas de calcular el estimador de diferencia de medias truncado

sim_dat1$rankY <- rank(sim_dat1$Y)
sim_dat1$Y_tc <- with(sim_dat1, ifelse(rankY == max(rankY), 
                                       Y[rankY == (max(rankY) - 1)], Y))
est_topcoded_1 <- with(sim_dat1, mean(Y_tc[Z == 1]) - mean(Y_tc[Z == 0]))
est_topcoded_2 <- coef(lm_robust(Y_tc ~ Z, data = sim_dat1, 
        se = "classical"))[["Z"]]
c(est_topcoded_1,est_topcoded_2)
```


## Luego simular otra aleatorización y estimar el ATE con los mismos estimadores

Ahora calcule su estimación con los mismos estimadores utilizando una aleatorización **diferente**. Dese cuenta que las respuestas difieren. Los estimadores están estimando el *mismo estimador* pero ahora utilizan una aleatorización diferente.
```{r echo=TRUE}
# hacer otra asignación aleatoria del tratamiento en DeclareDesign
# esto produce un nuevo conjunto de datos simulados con una asignación aleatoria diferente
sim_dat2 <- draw_data(base_design)
# el primer estimador (diferencia de medias)
coef(lm_robust(Y ~ Z, data = sim_dat2, se = "classical"))[["Z"]]
# el segundo estimador (diferencia de medias truncada)
sim_dat2$rankY <- rank(sim_dat2$Y)
sim_dat2$Y_tc <- with(sim_dat2, ifelse(rankY == max(rankY), 
        Y[rankY == (max(rankY) - 1)], Y))
coef(lm_robust(Y_tc ~ Z, data = sim_dat2, se = "classical"))[["Z"]]
```


## ¿Cómo se comportan nuestros estimadores en general para este diseño?

Nuestras estimaciones varían según las aleatorizaciones. ¿Varían nuestros dos estimadores  de la misma manera?
  
```{r diagnose, echo=TRUE, cache=TRUE}
## Combinar en un objeto diseño DeclareDesign
## Este tiene el diseño base, el estimando y luego nuestros dos estimadores
design_plus_ests <- base_design + estimandATE + diff_means + 
    diff_means_topcoded
## Correr 100 simulaciones (reasignaciones del tratamiento) y
## aplica los dos estimadores (diff_means y diff_means_topcoded)
diagnosis1 <- diagnose_design(design_plus_ests, 
                              bootstrap_sims = 0, sims = 100)
sims1 <- get_simulations(diagnosis1)
head(sims1[,-c(1:6)])
```


## ¿Cómo se comportan nuestros estimadores en general para este diseño?

Nuestras estimaciones varían según las aleatorizaciones. ¿Varían Nuestros dos estimadores  de la misma manera?
  ¿Cómo debemos interpretar esta trama?
  
```{r sim_plot, out.width=".8\\textwidth"}
sim_plot <- ggplot(sims1, aes(y = estimate, x = estimator, color = estimator)) +
  geom_boxplot() +
  geom_hline(yintercept = trueATE) +
  geom_point(aes(group = estimator)) +
  theme(text = element_text(size=20))
print(sim_plot)
```
## ¿Cuál estimador se acerca más a la verdad?

Una forma de elegir entre los estimadores es elegir el que esté más **cerca de la verdad** siempre que lo usemos, independientemente de la aleatorización específica.

Un estimador "insesgado" es aquel para el que **el promedio de las estimaciones en los diseños repetidos** es el mismo que el verdadero (o $E_R (\hat {\bar{\tau}}) = \bar{\tau}$ ). Un estimador no sesgado no tiene "ningún error sistemático" pero no garantiza la cercanía a la verdad.

Otra medida de cercanía es el **error cuadrático medio de la raíz** (RMSE, por sus siglas en inglés), que registra las distancias cuadráticas entre la verdad y las estimaciones individuales.

¿Qué estimador es mejor? (Uno está más cerca de la verdad en promedio (RMSE) y es más preciso. El otro no tiene un error sistemático: es insesgado).

```{r}
kableExtra::kable(reshape_diagnosis(diagnosis1, select = c("Estimator", "Bias", "RMSE", "SD Estimate", "Mean Se", "Power"))[,-c(1,2,4,5,6)])
```


## Estimadores sesgados e insesgados

Resumen:

 - Podemos *decidir* sobre los estimandos y estimadores
 
 - Un buen estimador trabaja bien independientemente de la aleatorización particular que se esté considerando de un diseño dado. El que *trabaja bien* puede significar que sea "insesgado" y/o un "error cuadrático medio bajo" (o "consistente", lo que significa que a medida que el tamaño de la muestra el estimador se acerca más al valor real).
 
 - Podemos aprender qué tan bien un estimador trabajo en un estudio dado simulando.

# Aleatorización en Bloques

## Los experimentos aleatorizados en bloques son una colección de mini-experimentos


¿Cuál es el estimando del **ATE** en un experimento aleatorizado en bloques?

Si pensamos en el ATE al nivel de la unidad: $(1/N) \sum_{i=1}^N y_{i,1} - y_{i,0}$ entonces podríamos equivalentemente re-expresar esto utilizando el ATE del bloque $j$ es $ATE_j$, como a continuación:

\[
ATE = \frac{1}{J}\sum^J_{j=1} \sum^{N_j}_{i=1} \frac{y_{i,1} - y_{i,0}}{N_j}  = \sum^J_{j=1} \frac{N_j}{N} ATE_j
\]


Y sería natural *estimar* esta cantidad ingresando lo que sí podemos calcular:
$\widehat{ATE} = \displaystyle\sum^J_{j=1} \frac{N_j}{N} \widehat{ATE}_j$

## Los experimentos aleatorizados en bloques son una colección de mini-experimentos

Y podríamos *definir* el error estándar del estimador también promediando los errores estándar dentro del bloque (si nuestros bloques son lo suficientemente grandes):

$SE(\widehat{ATE}) = \sqrt{\sum^J_{j=1} (\frac{N_{j}}{N})^2SE^2(\widehat{ATE}_j)}$


## Estimando el ATE en experimentos aleatorizados en bloques

Una opción para estimar es simplemente reemplazar $ATE_j$ con $\widehat{ATE}$:

```{r br1, echo=TRUE}
with(dat,table(b,Z))
```

Tenemos 6 unidades en el bloque `a`, 2 de los cuales son asignadas al tratamiento, y 4 unidades en el bloque `b`, 2 de las cuales son asignadas al tratamiento.

##  Estimando el ATE en experimentos aleatorizados en bloques

Una opción para estimar es simplemente reemplazar $ATE_j$ con $\widehat{ATE}$:

```{r br2, echo=TRUE}
datb <- dat %>% group_by(b) %>% summarize(nb=n(),pb=mean(Z),estateb=mean(Y[Z==1]) - mean(Y[Z==0]),
    ateb=mean(y1-y0),.groups="drop")
datb
## True ate by block:
with(dat,mean(y1-y0))
## This is another way to calculate the true ate
with(datb, sum( ateb*(nb/sum(nb))) )
```


##  Estimando el ATE en experimentos aleatorizados en bloques

Una opción es estimar el ATE total ajustando los pesos de acuerdo al tamaño de los bloque:

```{r br3, echo=TRUE}
## Showing that difference_in_means uses the blocksize weight.
e1 <- difference_in_means(Y~Z,blocks=b,data=dat)
e2 <- with(datb, sum( estateb*(nb/sum(nb))) )
c(coef(e1)[["Z"]],e2)
```


##  Estimando el ATE en experimentos aleatorizados en bloques


Dese cuenta que esto **no** es lo mismo que lo siguiente:

```{r br4, echo=TRUE}
## Ignorando los bloques
e3 <- lm(Y~Z,data=dat)
coef(e3)[["Z"]]

## Con efectos fijos de bloques
e4 <- lm(Y~Z+block,data=dat)
coef(e4)[["Z"]]
```

¿En qué se diferencian? (El primero ignora los bloques. El segundo usa un conjunto de pesos diferentes, creado usando las variables de "efectos fijos" o "indicadores" o variables "dummy")

## ¿Qué estimador deberíamos usar?

Ahora tenemos tres estimadores, cada uno con una estimación diferente (imaginando que todos apuntan al mismo estimador):

```{r echo=TRUE}
c(coef(e1)[["Z"]],coef(e3)[["Z"]], coef(e4)[["Z"]])
```

¿Qué estimador deberíamos usar para este diseño? Podemos configurar una simulación de DeclareDesign para resolver esto.

```{r blockdd0, cache=TRUE, echo=TRUE}
##declarar un nuevo diseño base que incluya el indicador de bloque b
base_design_blocks <- 
    # declare the population 
    declare_population(dat[, c("b","y0", "y1")]) +
    # Dígale a DD que b indica bloque y que asigne 2 unidades tratadas en cada bloque
    declare_assignment(m = 2,blocks = b, legacy = TRUE) + 
    # relación de las salidas potenciales con la realización de la variable de interés
    declare_potential_outcomes(Y ~ Z * y1 + (1 - Z) * y0)+
    # Variable Y observada y asignación al tratamiento
    declare_reveal(Y, Z)
```

## ¿Qué estimador deberíamos usar?

```{r blockdd1, echo=TRUE, cache=TRUE}
# El estimando es el valore promedio del tratamiento

estimandATEb <- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0))

# tres estimadores diferentes
est1 <- declare_estimator(Y ~ Z, inquiry = estimandATEb, model = lm_robust, 
    label = "Ignora bloques")
est2 <- declare_estimator(Y ~ Z, inquiry = estimandATEb, model = difference_in_means, blocks=b, 
    label = "DiM: con pesos por bloques")
est3 <- declare_estimator(Y ~ Z, inquiry = estimandATEb, model=lm_robust, 
    weights=(Z / Z_cond_prob) + ((1 - Z) / ( Z_cond_prob)), 
    label = "LM: con pesos por bloques")
```

## ¿Qué estimador deberíamos usar?


```{r blockdd1a, echo=TRUE, cache=TRUE}
# dos estimadores más
est4 <- declare_estimator(Y ~ Z, inquiry = estimandATEb, 
    model = lm_robust, fixed_effects=~b, label = "Pesos de precisión")
est5 <- declare_estimator(Y ~ Z + b, inquiry = estimandATEb, 
    model = lm_robust, label = "Pesos de precisión (LSDV)")


## El nuevo objeto de diseño tiene el diseño base, el estimado y cinco estimadores

design_blocks <- base_design_blocks + estimandATEb + 
  est1 + est2 + est3 + est4 + est5
```

Luego, corremos 10,000 simulaciones (reasignaremos el tratamiento 10,000 veces) y resumimos las estimaciones producidas por cada uno de estos cinco estimadores.

## ¿Qué estimador deberíamos usar?

```{r futurelibs, echo=FALSE}
## Esto para habilitar el procesamiento paralelo al realizar los diagnósticos.
## Tenga en cuenta que hemos activado la "caché" para algunos fragmentos de código para que no sean
## volver a ejecutar cada vez que cambiemos las diapositivas.
library(future)
library(future.apply)
```

```{r diagnosis2, echo=FALSE, cache=TRUE}

## Las siguientes líneas usan todos los núcleos de tu computadora para acelerar el cálculo

# plan(multicore)
set.seed(12345)
diagnosis2 <- diagnose_design(design_blocks, bootstrap_sims = 0, sims = 1000)
sims2 <- get_simulations(diagnosis2)
# plan(sequential)
```


¿Cómo debemos interpretar esta gráfica?

```{r sim_plot2, warning=FALSE, out.width=".9\\textwidth"}
sim_plot2 <- ggplot(sims2, aes(y = estimate, x = estimator, color = estimator)) +
  geom_boxplot() +
  geom_hline(yintercept = trueATE) +
  geom_point(aes(group = estimator)) +
  theme(text = element_text(size=20),axis.text.x = element_text(angle=45, hjust=1), 
      legend.position="none",legend.title = element_blank()) + 
  xlab("")
print(sim_plot2)
```

## ¿Qué estimador se acerca más a la verdad?

¿Qué estimador funciona mejor con este diseño y estos datos?

```{r blocktab}
blocktab <- reshape_diagnosis(diagnosis2, select = c("Estimator", "Bias", "RMSE","SD Estimate", "Mean Se", "Power",  "Coverage"))[,-c(1,2,4,5,6)]
kableExtra::kable(blocktab,col.names = c("Estimator","Bias","RMSE","SD Est","Mean SE","Power","Coverage"))
```

Tenga en cuenta que la cobertura no siempre es del 95% en todos los casos. Usamos 10,000 simulaciones, por lo que el error de simulación es de alrededor de $\pm 2 \sqrt{p (1-p)/10000} $ o, digamos, para una cobertura calculada como .93, una simulación diferente podría haber producido fácilmente `r .93 -2 * sqrt(.93 * (1-.93) / 10000) `o` r .93 + 2 * sqrt(.93 * (1-.93) / 10000) `(o rara vez habría producido números de cobertura fuera de ese rango solo por casualidad).




# Aleatorización por conglomerados

## En los experimentos aleatorizados por conglomerados, las unidades se asignan al azar como un grupo (conglomerado) al tratamiento {.allowframebreaks}

- **Ejemplo 1:** una intervención se asigna al azar entre vecindarios, por lo que **todos** los hogares de un vecindario se asignarán a la misma condición de tratamiento, pero a diferentes vecindarios se les asignarán diferentes condiciones de tratamiento.
- **Ejemplo 2:** una intervención se asigna al azar entre personas y se miden datos sobre cada personas cuatro veces después del tratamiento, por lo que nuestro conjunto de datos contiene cuatro filas por persona.
- **No es un ejemplo 1:** Se seleccionan vecindarios  para un estudio. Dentro de cada vecindario, aproximadamente la mitad de las personas están asignadas al tratamiento y la otra mitad al control. (¿Qué tipo de estudio es este? No es un estudio aleatorizado por conglomerados).
- **No es un ejemplo 2:** una intervención se asigna al azar a algunos vecindarios y a otros no, entre las variables de interés hay mediciones de la confianza en el gobierno a nivel del vecindario y el área total de tierra en el vecindario dedicada a jardines. (A veces, un experimento aleatorizado por conglomerados se puede convertir en un experimento aleatorizado simple. O puede contener más de un posible enfoque de análisis e interpretación).

¿Cómo podría diferir la distribución de los estimadores y las estadísticas de prueba de un experimento en el que se aleatorizan unidades individuales (y no conglomerados)?

## Estimación del ATE en experimentos aleatorizados por conglomerados

Problemas de sesgo en experimentos aleatorizados por conglomerados:

- Cuando los conglomerados tienen el mismo tamaño, el estimador de diferencia de medias habitual es insesgado.

- Pero tenga cuidado cuando los conglomerados tienen diferentes números de unidades o si hay muy pocos conglomerados porque los efectos del tratamiento pueden estar correlacionados con el tamaño del conglomerado.

- Cuando el tamaño del conglomerado está relacionado con las salidas potenciales, el estimador habitual de diferencias de medias está sesgado. <https://declaredesign.org/blog/bias-cluster-randomized-trials.html>

## Estimación del error estándar para el ATE en experimentos aleatorizados por conglomerados {.allowframebreaks}

- **Inferencias estadísticas engañosas:** El error estándar predeterminado generalmente subestimará la precisión en dichos diseños y por lo tanto producirá pruebas con tasas de falsos positivos  demasiado altas (o, de manera equivalente, tasas de cobertura de intervalos de confianza que son demasiado bajas).

- Los "errores estándar robustos para conglomerados" implementados en softwares comunes funcionan bien **cuando el número de clústeres es grande** (como más de 50 en algunos estudios de simulación).

- Los errores estándar predeterminados apropiados para conglomerados en `lm_robust` (los SE de` CR2`) funcionan mejor que el enfoque común en Stata (al momento en el que se escriben estas presentación).
- El wild-bootstrap ayuda a controlar las tasas de error, pero cede el poder estadístico mucho más de lo que quizás sea necesario en un estudio aleatorizado por conglomerados donde se puede hacer inferencia de aleatorización directamente.

- En caso de  no estar seguro, se pueden producir valores $p$ mediante simulación directa (inferencia de aleatorización directa) para ver las estimaciones robustas para conglomerados son correctas

En general, vale la pena realizar una simulación para estudiar el desempeño de sus estimadores, pruebas e intervalos de confianza si se tiene alguna inquietud o duda.

## Un ejemplo de estimación

```{r makedatclus, echo=FALSE, results="hide"}
## vea https://declaredesign.org/blog/bias-cluster-randomized-trials.html
## para más sobre esto
N_clusters <- 10  #
n_indivs <- c(100,10) # tamaño posible de los conglomerado
thepop <- declare_population(clus_id = add_level(
            # defina el número de conglomerados
            N = N_clusters,
            # 1/5 conglomerados tiene 100 individuos, 4/5 conglomerados tiene  10 individuos
            cl_size = rep(n_indivs, c(N/5, N - N/5)), 
            cl_sizeF = factor(cl_size),
            
# Cada grupo tiene un nivel medio diferente (u) y una variabilidad de fondo diferente (sd de u)

            effect = ifelse(cl_size == 100, .1, 1)),
            indiv = add_level(N = cl_size,
                u = rnorm(N, mean=log(cl_size), sd = effect)))

theys <- declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + effect)

thetarget_indiv <- declare_estimand(ATE_indiv = mean(Y_Z_1 - Y_Z_0))

## Asignación aleatoria completa para los conglomerados
theassign <- declare_assignment(clusters = clus_id, legacy = TRUE)

thereveal <-   declare_reveal(Y, Z)

## 7  estimadores diferentas
est1 <-   declare_estimator(Y ~ Z, inquiry = "ATE_indiv", clusters = clus_id,
                    model = lm_robust, label = "Y~Z, CR2 SE")

est2 <- declare_estimator(Y ~ Z, inquiry = "ATE_indiv",
                    model = lm_robust, label = "Y~Z, HC2 SE")

est3 <- declare_estimator(Y ~ Z, inquiry = "ATE_indiv",
                    model = lm_robust,se_type="classical", label = "Y~Z, IID SE")

est4 <- declare_estimator(Y ~ Z + cl_sizeF, inquiry = "ATE_indiv",clusters = clus_id,
                    model = lm_robust, label = "Y~Z+clus_size_fixed_effects, CR2 SE")

est5 <- declare_estimator(Y ~ Z, inquiry = "ATE_indiv", fixed_effects=~cl_sizeF,clusters = clus_id,
                    model = lm_robust, label = "Y~Z, fixed_effects=~clus_size_fixed_effects, CR2 SE ")

est6 <-  declare_estimator(Y ~ Z, inquiry = "ATE_indiv", covariates=~cl_size,clusters = clus_id,
                    model = lm_lin, label = "Y~Z*I(clus_size-mean(clus_size)), CR2 SE")

est7 <-  declare_estimator(Y ~ Z, inquiry = "ATE_indiv", weight=cl_size,clusters = clus_id,
                    model = lm_robust, label = "Y~Z, weight=clus_size, CR2 SE")

### Some experimental stuff here:
## remotes::install_github("markmfredrickson/RItools",ref="proj1-balT")
## est7tmp <-  balanceTest(Z~Y+cluster(clus_id),data=dat1,report="all")
##
## est7fn <- function(data){
##     bt <- balanceTest(Z~Y+cluster(clus_id),data=data,report="all")
##     resdat <- data.frame(estimate=bt$results[,"adj.mean diff",])
##     return(resdat)
## }
## est7fn <- function(data){
##     thelme <- lmer(Y~Z+(1|clus_id),data=data)
##     cilme <- confint(thelme)
##     lmecoef <- summary(thelme)$coefficients["Z",]
##     resdat <- data.frame(estimate=lmecoef["Estimate"],
##         std.error=lmecoef["Std. Error"],
##             statistic=lmecoef["t value"],
##             p.value=NA,
##         conf.low=min(cilme["Z",]),
##         conf.high=max(cilme["Z",]))
##     return(resdat)
## }
##
## est7 <- declare_estimator(handler=tidy_estimator(est7fn),label="mlm: rand intercept")

des <- thepop + theys + theassign + thereveal

set.seed(12345)
dat1 <- draw_data(des)

head(dat1)

table(dat1$clus_id)
with(dat1,table(clus_id,Z))
dat1 %>% group_by(clus_id) %>% summarize(mean(Y_Z_1 - Y_Z_0))

## g1 <- ggplot(data=dat1,aes(x=Y,group=clus_id,fill=clus_id,color=clus_id))+
##     geom_density()
## g1

est1(dat1)
est2(dat1)
est3(dat1)
est4(dat1)
est5(dat1)
est6(dat1)
est7(dat1)

```

Imagine que tenemos datos de 10 grupos con 100 personas (para 2 grupos) o 10 personas por grupo (para 8 grupos). El tamaño total de los datos es `r nrow (dat1)`.

```{r}
tmp <- dplyr::filter(dat1,clus_id %in% c("03","01")) %>% group_by(clus_id) %>%
    sample_n(3) %>% arrange(clus_id,indiv) %>% select(clus_id,indiv,Y_Z_0,Y_Z_1,Z,Y)

tmp
```
## Un ejemplo de estimación

¿Qué estimador deberíamos utilizar? ¿Qué prueba debemos utilizar? ¿En que nos deberíamos basar para elegir entre estos enfoques?

```{r clusest, echo=TRUE}
lmc1 <- lm_robust(Y~Z,data=dat1)
lmc2 <- lm_robust(Y~Z,clusters=clus_id,data=dat1)
lmc3 <- lm_robust(Y~Z+cl_sizeF,clusters=clus_id,data=dat1)
tidy(lmc1)[2,]
tidy(lmc2)[2,]
tidy(lmc3)[2,]
```



## Utilice la simulación para evaluar estimadores y pruebas

Si observa el código de las diapositivas, verá que simulamos el diseño 5000 veces, calculando cada vez una estimación y un intervalo de confianza para diferentes estimadores del ATE.

```{r simdesign, warning=FALSE, results="hide"}
des_plus_est <- des + thetarget_indiv + est1 + est2 + est3 + est4 + est5 + est6 + est7
des_plus_est
```

```{r diag_clust, cache=TRUE, warning=FALSE}
set.seed(12346)
plan(multicore)
diag_clus <- diagnose_design(des_plus_est,bootstrap_sims = 0, sims=1000)
sim_clus <- get_simulations(diag_clus) # simulate_design(des_plus_est,sims=1000)
trueclusATE <- thetarget_indiv(dat1)[["estimand"]]
plan(sequential)
```


```{r cluster_sim_res}
## Dese cuenta que el estimador lin es bueno pero a veces no puede dar una respuesta
res_clus <- sim_clus %>% na.omit() %>% group_by(estimator) %>%
    summarize(bias = mean(estimate - estimand),
     rmse = sqrt(mean((estimate - estimand) ^ 2)),
     power = mean(p.value < .05),
     coverage = mean(estimand <= conf.high & estimand >= conf.low),
     # mean_estimate = mean(estimate),
     sd_estimate = sd(estimate),
     mean_se = mean(std.error))
res_clus[2,"estimator"] <- "Y~Z, cl_size fe, CR2"
res_clus[6,"estimator"] <- "Y~Z*I(cl_size-mean(cl_size)), CR2"
res_clus[7,"estimator"] <- "Y~Z+cl_sizeF, CR2"
res_clus$estimator <- gsub(" SE","",res_clus$estimator)
```

```{r showresclus1}
kableExtra::kable(res_clus[,c(1,5:7)], digits=2,booktabs=TRUE,linesep="",caption="
Estimador y  prueba de desempeño con 5000 simulaciones del diseño aleatorio por conglomerados para diferentes estimadores e intervalos de confianza")
```




## Utilice la simulación para evaluar estimadores y pruebas

¿Qué debemos aprender de esta tabla? (¿Sesgo? ¿Cercanía a la verdad?)

```{r showresclus2}
kableExtra::kable(res_clus[,c(1:3)], digits=3,booktabs=TRUE,linesep="",caption="Estimador y prueba de desempeño con 5000 simulaciones del diseño aleatorio por conglomerados para diferentes estimadores e intervalos de confianza")
```

## Utilice la simulación para evaluar estimadores y pruebas

¿Cómo debemos interpretar esta gráfica?

```{r sim_plot_clus, warning=FALSE, out.width=".95\\textwidth"}
sim_plot3 <- ggplot(sim_clus, aes(y = estimate, x = estimator, color = estimator)) +
  geom_boxplot() +
  coord_flip()+
  geom_hline(yintercept = trueclusATE) +
  geom_point(aes(group = estimator)) +
  theme(text = element_text(size=20),
      legend.position="none",legend.title = element_blank()) + 
  ylab("")
print(sim_plot3)
```

## Resumen de la estimación y las pruebas en ensayos aleatorizados por conglomerados

 - Los ensayos aleatorios por conglomerados plantean problemas especiales para los enfoques estándar de estimación y prueba.
 
 - Si la aleatorización es a nivel del conglomerado, la incertidumbre surge de la aleatorización a nivel del conglomerado.
 
 - Si tenemos suficientes conglomerados, entonces uno de los errores estándar "robustos para conglomerados" puede ayudarnos a producir intervalos de confianza con la cobertura correcta. **Los errores estándar robustos para conglomerados requiere que haya muchos conglomerados**.
 
 - Si el tamaño del conglomerado (o alguna característica) está relacionado con el tamaño del efecto, entonces puede haber sesgo (y necesitamos ajustar de alguna manera).


# Variables de Interés Binarias

## Variables de interés binarias: configurar los datos para la simulación en DeclareDesign

```{r setupbin, echo=TRUE}
# Tamaño de la población
N <- 20
# declarar la población
thepop_bin <- declare_population(N=N, x1 = draw_binary(prob = .5, N = N),
x2=rnorm(N))
# declarar las salidas potenciales
thepo_bin <- declare_potential_outcomes(Y ~ rbinom(n = N, size = 1, 
                                                   prob = 0.5 + 0.05 * Z + x1*.05))
# dos cantidades objetivos: diferencia de medias or diferencia de log-odds
thetarget_ate <- declare_estimand(ate = mean(Y_Z_1 - Y_Z_0))
thetarget_logodds <- declare_estimand(
    logodds = log(mean(Y_Z_1)/(1-mean(Y_Z_1))) - 
    log(mean(Y_Z_0)/(1-mean(Y_Z_0)))
)
```

## Resultados binarios: configurar los datos para la simulación en DeclareDesign

```{r setupbin2, echo=TRUE}
# declarar cómo se asgina el tratamiento
# m unidadess asignadas to los niveles de tratamiento Z
theassign_bin <- declare_assignment(m=floor(N/3), legacy = TRUE)
# declarar cuáles variables son reveladas para los diferentes valores de Z
thereveal_bin <- declare_reveal(Y,Z)
# Reunir todo lo que tenemos: población, salidas potenciales, asignación,
## valores revelados conectados a Z
des_bin <- thepop_bin+thepo_bin+theassign_bin+thereveal_bin
# Una realización de los datos (aleatorizar una vez el tratamiento )
set.seed(12345)
dat2 <- draw_data(des_bin)
```

## Variables de interés binarias: Estimandos I

¿Cómo interpretar las siguientes cantidades reales o estimandos?(`Y_Z_1`, `Y_Z_0` son salidas potenciales, `Y` es observada, `x1`, `x2` are covariables, `Z` es la asignación al tratamiento. Aquí $N$=`r nrow(dat2)`.


```{r dat2echo, echo=TRUE}
## Veámos las primeras 6 observaciones:
head(dat2[,-7])
```


### Variables de interés binarias: Estimandos II

How would we interpret the following true
quantities or estimands? (`Y_Z_1`, `Y_Z_0` are potential
outcomes, `Y` is observed, `x1`, `x2` are covariates, `Z` is treatment assignment. Here $N$=`r nrow(dat2)`.

```{r bin1, echo=TRUE}
ate_bin <- with(dat2,mean(Y_Z_1 - Y_Z_0))
bary1  <- mean(dat2$Y_Z_1)
bary0 <- mean(dat2$Y_Z_0)
diff_log_odds_bin <- with(dat2, 
    log(bary1/(1-bary1)) - log(bary0/(1-bary0)))
c(bary1=bary1,bary0=bary0,true_ate=ate_bin,
    true_diff_log_odds= diff_log_odds_bin)
```

## Variables de interés binarias: Estimandos III

¿Desea estimar la diferencia en logg-odds?

\begin{equation}
\delta = \log \frac{\bar{y}_{1}}{1-\bar{y}_{1}} - \log \frac{ \bar{y}_0}{1- \bar{y}_0}
\end{equation}

¿O la diferencia de proporciones?

\begin{equation}
\bar{\tau} = \bar{y}_{1} - \bar{y}_0
\end{equation}

Recuerde que $\bar{y}_1$ que es la *proporción* de $y_{1}=1$ en los datos.

@freedman2008randomization nos muestra que el estimador del coeficiente logit es un estimador sesgado de la diferencia en el estimado log-odds. También muestra un estimador insesgado de ese estimando.

Sabemos que la diferencia de proporciones en la muestra debe ser un estimador insesgado de la diferencia de proporciones.


## Un ejemplo de estimación I

¿Cómo debemos interpretar las siguientes estimaciones? (¿Cuál es la diferencia de
medias que el estimador requiere en términos de supuestos? ¿Qué hace la logística
estimador de regresión requiere en términos de supuestos?)

```{r estexample, echo=TRUE}
lmbin1 <- lm_robust(Y~Z,data=dat2)
glmbin1 <- glm(Y~Z,data=dat2,family=binomial(link="logit"))

tidy(lmbin1)[2,]
tidy(glmbin1)[2,]
```

## Un ejemplo de estimación II

¿Qué pasa con las covariables? ¿Por qué usar covariables?

```{r estexample2, echo=TRUE}
lmbin2 <- lm_robust(Y~Z+x1,data=dat2)
glmbin2 <- glm(Y~Z+x1,data=dat2,family=binomial(link="logit"))

tidy(lmbin2)[2,]
tidy(glmbin2)[2,]
```

## Un ejemplo de estimación III

Comparemos nuestros estimados

```{r estexample3, echo=TRUE}
c(dim=coef(lmbin1)[["Z"]],
  dim_x1=coef(lmbin2)[["Z"]],
  glm=coef(glmbin1)[["Z"]],
  glm_x1=coef(glmbin2)[["Z"]])
```

## Un ejemplo de estimación: Los estimadores de Freedman I

Sin covariables:
```{r pluginest, echo=TRUE }
freedman_plugin_estfn1 <- function(data){
    glmbin <- glm(Y~Z,data=dat2,family=binomial(link="logit"))
    preddat <- data.frame(Z=rep(c(0,1),nrow(dat2)))
    preddat$yhat <- predict(glmbin,newdata=preddat,type="response")
    bary1 <- mean(preddat$yhat[preddat$Z==1])
    bary0 <- mean(preddat$yhat[preddat$Z==0])
    diff_log_odds <- log(bary1/(1-bary1)) - log(bary0/(1-bary0))
    return(data.frame(estimate=diff_log_odds))
}
```

## Un ejemplo de estimación: Los estimadores de Freedman II

Con covariables:
```{r pluginest2, echo=TRUE }
freedman_plugin_estfn2 <- function(data){
    N <- nrow(data)
    glmbin <- glm(Y~Z+x1,data=data,family=binomial(link="logit"))
    preddat <- data.frame(Z=rep(c(0,1),each=N))
    preddat$x1 <- rep(data$x1,2)
    preddat$yhat <- predict(glmbin,newdata=preddat,type="response")
    bary1 <- mean(preddat$yhat[preddat$Z==1])
    bary0 <- mean(preddat$yhat[preddat$Z==0])
    diff_log_odds <- log(bary1/(1-bary1)) - log(bary0/(1-bary0))
    return(data.frame(estimate=diff_log_odds))
}
```

Comparemos nuestros estimados de seis estimadores diferentes


```{r echo=FALSE}
c(dim=coef(lmbin1)[["Z"]],
  dim_x1=coef(lmbin2)[["Z"]],
  glm=coef(glmbin1)[["Z"]],
  glm_x1=coef(glmbin2)[["Z"]],
freedman=freedman_plugin_estfn1(dat2)[["estimate"]],
freeman_x1=freedman_plugin_estfn2(dat2)[["estimate"]]
)
```


```{r tmleapproach, eval=FALSE}
## Aquí hay otro enfoque para usar el estimador de complementos pero permitiendo errores estándar, etc.
## No requiere una función escrita a mano como las que se usaron anteriormente.

library(tmle)
Y <- as.matrix(dat2$Y,ncol=1)
A <- as.matrix(dat2$Z,ncol=1)
W <- as.matrix(dat2[,c("x1","x2")],ncol=1)
colnames(W) <- paste("W",1:2,sep="")
tmle1 <- tmle(Y=Y,A=A,W=W,
              family="binomial",Qform=Y~A,gform=A~1,cvQinit=FALSE,
              Q.SL.library = "SL.glm", g.SL.library="SL.glm",g.Delta.SL.library = "SL.glm")

tmle1$estimates$ATE
tmle1$estimates$OR

tmle2 <- tmle(Y=Y,A=A,W=W,
              family="binomial",Qform=Y~A+W1,gform=A~1,cvQinit=FALSE,#V=0,
              Q.SL.library = "SL.glm", g.SL.library="SL.glm",g.Delta.SL.library = "SL.glm")

tmle2$estimates$ATE
tmle2$estimates$OR
```

## Un ejemplo del uso de DeclareDesign para evaluar nuestros estimadores I

```{r ddbinsetup, echo=TRUE}
# declarar 4 estimadores para DD
# primer estimador: regresión linear con ATE como cantidad objetivo
estb1 <- declare_estimator(Y~Z,model=lm_robust,label="lm1:Z",
                           estimand=thetarget_ate )
# segundo estimador: regresión linear con covariables con ATE cantidad objetivo
estb2 <- declare_estimator(Y~Z+x1,model=lm_robust,label="lm1:Z,x1",
                           estimand=thetarget_ate)
# tercer estimador: regresión logística con log odds cantidad objetivo
estb3 <- declare_estimator(Y~Z,model=glm,family=binomial(link="logit"),
                           label="glm1:Z",estimand=thetarget_logodds)
# cuadro estimador: regresión logística con covaribles con log odds cantidad objetivo 
estb4 <- declare_estimator(Y~Z+x1,model=glm,family=binomial(link="logit"),
                           label="glm1:Z,x1", estimand=thetarget_logodds)
```


## Un ejemplo del uso de DeclareDesign para evaluar nuestros estimadores II

```{r ddbinsetup2, echo=TRUE}
# Pull together: des_bin is population, potential outcomes, assignment, 
# outcome values connected to Z.  We add the two targets and four estimators.
des_bin_plus_est <- des_bin + thetarget_ate + thetarget_logodds + 
  estb1 + estb2 + estb3 + estb4
```

```{r diagnosis_bin, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
## Las siguientes lineas de código utilizan todos los cores de su computador para hacer más rápido la computación
library(future)
library(future.apply)
# plan(multiprocess)
set.seed(12345)
diagnosis_bin <- diagnose_design(des_bin_plus_est, bootstrap_sims = 0, sims = 1000)
sims_bin <- get_simulations(diagnosis_bin)
trueATE_bin <- thetarget_ate(dat2)[["estimand"]]
truelo_bin <- thetarget_logodds(dat2)[["estimand"]]
# plan(sequential)
```

## Usando simulación para evaluar nuestros estimadores

¿Cómo debemos interpretar esta gráfica?  (La diferencias en escala dificultan interpretación.)
  
```{r sim_plot_bin, out.width=".95\\textwidth"}
estimand_dat <- sims_bin %>% group_by(estimand) %>% summarize(meanestimand=mean(estimand))
sim_plot_bin <- ggplot(sims_bin, aes(y = estimate, x = estimator, color = estimator)) +
  geom_boxplot() +
  geom_point() +
  facet_wrap(~estimand,scales="free") +
  geom_hline(data=estimand_dat,aes(yintercept=meanestimand)) +
  theme(text = element_text(size=20),
      legend.position="none",legend.title = element_blank())
print(sim_plot_bin)
```

## ¿Cuál es el estimador está más cerca a la verdad?

¿Cuál estimador funciona mejor para este diseño y estos datos?
  
```{r bin_sim_res}
## Dese cuenta que el lin estimador funciona bien pero a veces no puede dar una respuesta
res_bin <- sims_bin %>% group_by(estimator,estimand) %>%
  summarize(bias = mean(estimate - estimand),
            rmse = sqrt(mean((estimate - estimand) ^ 2)),
            power = mean(p.value < .05),
            coverage = mean(estimand <= conf.high & estimand >= conf.low,na.rm=TRUE),
            # mean_estimate = mean(estimate),
            sd_est = sd(estimate),
            mean_se = mean(std.error))
names(res_bin)[1:2] <- c("est","estimand")
```

```{r showresbin1}
kableExtra::kable(res_bin, digits=3,booktabs=TRUE,linesep="",caption="Estimador y  prueba de desempeño con 5000 simulaciones del diseño aleatorio por conglomerados para diferentes estimadores e intervalos de confianza.")
```


# Otros Temas sobre Estimación

## Ajuste de covarianza: Estimandos


En general, simplemente "controlar" produce un estimador sesgado del estimado ATE **o** ITT. Vea, por ejemplo, @lin_agnostic_2013 y @freedman2008rae.
@lin_agnostic_2013 muestra cómo reducir este sesgo y, lo que es más importante, este sesgo tiende a ser pequeño a medida que aumenta el tamaño de la muestra.

# Conclusión

## Reflexiones finales sobre los conceptos básicos de la estimación

- Las estimandos causales contrafactuales son funciones salidas potenciales no observadas

- Los estimadores son recetas o fórmulas computacionales que utilizan datos observados para
aprender acerca de un estimando.

- Los buenos estimadores producen estimaciones cercanas al estimando real

- (Relación de la estimación con las pruebas) Los errores estándar de los estimadores nos permiten
para calcular intervalos de confianza y valores $p$. Ciertos estimadores tienen
errores estándar más grandes o más pequeños (o más o menos correctos).

- Puede evaluar la utilidad de un estimador elegido para un estimador elegido mediante simulación.
# Efectos causales que difieren por grupos o covariables

## Efectos que se diferencian por grupos I

Si nuestra teoría sugiere que los efectos deben diferir según el grupo, ¿cómo podemos evaluar la evidencia a favor o en contra de tales afirmaciones?

 - Podemos **diseñar**  una evaluación de una teoría creando un
   estudio aleatorizado en bloque; los bloques están definidos los grupos relevantes según la teoría.
   
 - Podemos **planificar** para dicha evaluación mediante (1) **preinscripción específica
   análisis de subgrupos** (si bloqueamos o no ese grupo en la
   fase de diseño) y (2) asegurarse de medir la pertenencia al grupo durante los datos la recolección inicial de datos previa al tratamiento
   
   
## Efectos que se diferencian por grupos II
 - Si no lo hemos planeado con anticipación, los análisis específicos de subgrupos pueden ser útiles como
   exploraciones, pero no deben entenderse como confirmatorias: también pueden
   crear fácilmente problemas de probar demasiadas hipótesis, por lo tanto, inflar la
   tasa de falsos positivos.
 
 - **No debemos utilizar grupos formados por tratamiento**. (Esto es "análisis de mediación" o "condicionamiento de variables posteriores al tratamiento" y le dedicamos un módulo propio).

# Efectos causales cuando no controlamos la intensidad de la dosis

## Definiendo  efectos causales I

Imagine un experimento de comunicación puerta a puerta en el que algunas casas se asignan al azar para recibir una visita. Tenga en cuenta que ahora usamos $Z$ y $d$ en lugar de $T$.

 - $Z_i$ es la asignación aleatoria a una visita ($Z_i = 1$) o no ($Z_i = 0$).
 - $d_ {i, Z_i = 1} = 1$ significa que la persona $i$ abriría la puerta para tener una conversación cuando se le asigne una visita.
 - $d_{i, Z_i = 1} = 0$ significa que la persona $i$ no abriría la puerta para tener una conversación cuando se le asigne una visita.
 - Abrir la puerta es un resultado del tratamiento.
 
\begin{center}
\begin{tikzcd}[ampersand replacement=\&]
Z  \arrow[from=1-1,to=1-2, "\ne 0"] \arrow[from=1-1, to=1-4, bend left, "\text{0 (exclusion)}"] \& d  \arrow[from=1-2,to=1-4] \& \& y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{0 (as if randomized)}"]  \arrow[from=2-1,to=1-2] \arrow[from=2-1,to=1-4]
\end{tikzcd}
\end{center}

## Definiendo efectos causales II

 - $y_ {i, Z_i = 1, d_ {i, Z_i = 1} = 1}$ es el resultado potencial para las personas a las que se les asignó una visita y que sí abrieron la puerta. ("los que cumplen" o "siempre tomadores")
 
 - $y_{i, 1, d_ {i, Z_i = 1} = 0}$ son las salidas potencial para las personas a las que se les asignó una visita y que no abrieron la puerta. ("los que nunca lo toman" o "los que desafian")
 
 - $ y_ {i, 0, d_ {i, 0} = 1} $ es el resultado potencial para las personas a las que no se les asignó una visita y que abrieron la puerta. ("los que desafian" o "los que siempre lo toman")
 
 - $ y_ {i, 0, d_ {i, 0} = 0} $ es el resultado potencial para las personas a las que no se les asignó una visita y que no habrían abierto la puerta. ("los que cumplen" o "los que nunca lo toman")

## Definición de efectos causales III
 También podríamos escribir $ y_{i, Z_i = 0, d_ {i, Z_i = 1} = 1}$ para las personas a las que no se les asignó una visita pero que habrían abierto la puerta si se les hubiera asignado una visita, etc.

En este caso, podemos simplificar nuestras salidaspotenciales:

  - $y_ {i, 0, d_ {i, 1} = 1} = y_ {i, 0, d_ {i, 1} = 0} = y_ {i, 0, d_ {i, 0} = 0}$ porque su resultado es el mismo independientemente de cómo no abra la puerta.


## Definición de efectos causales IV

Podemos simplificar las formas en que las personas reciben una dosis del tratamiento como tal
(donde $d$ es minúscula reflejando la idea de que si abre la puerta
cuando se visita o no es un atributo fijo como una salida potencial).

 - $Y$: variable de interés ($y_ {i, Z}$ o $y_ {i, Z_i = 1}$ para la salida potencial de
   tratamiento por persona $ i $, fijo)
 - $X$: covariable/variable de referencia
 - $Z$: asignación de tratamiento ($ Z_i = 1 $ si se asigna a una visita, $ Z_i = 0 $ si no se
   asigna a una visita)
 - $D$: tratamiento recibido ($D_i = 1$ si contesta el teléfono, $D_i = 0$ si la persona $i$
   dd no abrir la puerta) (usando $ D $ aquí porque $ D_i = d_ {i, 1} Z_ {i} + d_ {i, 0} (1-Z_i) $)

## Definición de efectos causales V

Tenemos dos efectos causales de $Z$: $ Z \rightarrow Y $ ($ \delta $, ITT, ITT $ _Y $) y $ Z\rightarrow D $ (GG
llame a esto ITT$_D $).

Y diferentes tipos de personas pueden reaccionar de manera diferente al intento de mover la
dosis con el instrumento.

\centering
\begin{tabular}{llcc}
                       &        & \multicolumn{2}{c}{$Z=1$} \\
		       &       & $D=0$ & $D=1$ \\
		       \midrule
\multirow{2}{*}{$Z=0$} & $D=0$ & Never taker & Complier \\
                       & $D=1$ & Defier     & Always taker \\
		       \bottomrule
\end{tabular}


## Definiendo efectos causales VI


The $ITT=ITT_Y=\delta= \bar{y}_{Z=1} - \bar{y}_{Z=0}$.

\medskip

Pero, en este diseño, $\bar {y}_{Z = 1} = \bar{y}_ {1}$ se divide en pedazos: el resultado de
aquellos que abrieron la puerta (Cumplidores y Siempre tomadores y Desafiadores). Escribir
$p_C$ para la proporción de cumplidores en el estudio.

\begin{equation}
\bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N + (\bar{y}_1|D)p_D.
\end{equation}

 $\bar{y}_{0}$ también se divide en pedazos:

\begin{equation}
\bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_{0}|N)p_N + (\bar{y}_0|D)p_D.
\end{equation}

##  Definiendo efectos causales VII
Entonces, el ITT en sí mismo es una combinación de los efectos de $ Z $ en $ Y $ dentro de estos
diferentes grupos (imagina sustituyéndolos y luego reorganizándolos para que podamos
tener un conjunto de ITT, uno para cada tipo de asignatura). Pero, aún podemos estimarlo porque tenemos insesgados
estimadores de $ \ bar {y} _1 $ y $ \ bar {y} _0 $ dentro de cada tipo.

## Aprendiendo sobre el ITT I

Primero, aprendamos sobre el efecto de la política en sí. Para anotar el
ITT, no es necesario que consideremos todos los tipos anteriores. No tenemos desafiantes
($ p_D = 0 $) y sabemos que el ITT tanto para los que siempre toman como para los que nunca toman es 0.

\begin{equation}
\bar{y}_{1}=(\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N
\end{equation}

\begin{equation}
\bar{y}_{0}=(\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N
\end{equation}

## Aprendiendo sobre ITT II

Primero, aprendamos sobre el efecto de la política en sí. Para anotar el
ITT, no es necesario que consideremos todos los tipos anteriores. No tenemos desafiantes
($ p_D = 0 $) y sabemos que el ITT tanto para los que siempre toman como para los que nunca toman es 0.


\begin{align}
ITT    = & \bar{y}_{1} - \bar{y}_{0} \\
        = & ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - \\
       & ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
       \intertext{collecting each type together --- to have an ITT for each type}
       = & ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) + \\
       & ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
       = & \left( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C) \right)p_C   +  \\
       & \left( (\bar{y}_{1}|A)- (\bar{y}_{0}|A) \right)p_A  +  \left( (\bar{y}_1|N) - (\bar{y}_{0}|N) \right)p_N
\end{align}

## Learning about the ITT III

\begin{align}
ITT     = &   \bar{y}_{1} - \bar{y}_{0} \\
        = &  ( (\bar{y}_{1}|C)p_C + (\bar{y}_{1}|A)p_A + (\bar{y}_1|N)p_N ) - \\
       & ( (\bar{y}_{0}|C)p_C + (\bar{y}_{0}|A)p_A + (\bar{y}_{0}|N)p_N )  \\
        = &   ( (\bar{y}_{1}|C)p_C -  (\bar{y}_{0}|C)p_C )  +   ( (\bar{y}_{1}|A)p_A - (\bar{y}_{1}|A)p_A ) + \\
       & ( (\bar{y}_1|N)p_N  - (\bar{y}_{0}|N)p_N ) \\
        = &   ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C   +   ( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A  + \\
       & ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N
\end{align}


## Learning about the ITT IV

And, if the effect of the dose can only occur for those who open the door, and you can only open the door when assigned to do so then:

\begin{equation}
( (\bar{y}_{1}|A)- (\bar{y}_{0}|A))p_A = 0  \text{ and } ( (\bar{y}_1|N) - (\bar{y}_{0}|N) )p_N = 0
\end{equation}

And

\begin{equation}
ITT =  ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C  = ( CACE ) p_C.
\end{equation}

## El efecto causal promedio del cumplidor I

También nos gustaría aprender sobre el efecto causal de abrir la puerta y
tener la conversación, el efecto teóricamente interesante.

Pero esta comparación se confunde con $ x $: un simple $ \ bar {Y} | D = 1 - \ bar {Y} | D = 0 $
La comparación nos informa sobre las diferencias en el resultado debido a $ x $ además de
la diferencia causada por $ D $. (Números a continuación de algunos datos simulados)

\begin{center}
\begin{tikzcd}[ampersand replacement=\&]
Z  \arrow[from=1-1,to=1-2] \arrow[from=1-1, to=1-4, bend left, "\text{0 (exclusion)}"] \& D  \arrow[from=1-2,to=1-4] \& \& y \\
(x_1 \ldots x_p) \arrow[from=2-1,to=1-1, "\text{-.006 (as if randomized)}"]  \arrow[from=2-1,to=1-2, ".06"] \arrow[from=2-1,to=1-4, ".48"]
\end{tikzcd}
\end{center}


## The complier average causal effect II

```{r cors, eval=FALSE, echo=TRUE, results="hide"}
with(dat, cor(Y, x)) ## can be any number
with(dat, cor(d, x)) ## can be any number
with(dat, cor(Z, x)) ## should be near 0
```

Pero acabamos de ver eso, en este diseño y con estas suposiciones (incluida una
Supuesto de SUTVA) que
$ITT =  ( (\bar{y}_{1}|C) -  (\bar{y}_{0}|C))p_C  = (CACE) p_C$, so we can define $CACE=ITT/p_C$.


## Cómo calcular el ITT y CACE / LATE I

```{r simivdesign, echo=FALSE}
prob_comply <- .8
tau <- .5

the_pop <- declare_population(N=100,
    X = sample(1:4, N, replace = TRUE),
    u = rnorm(N),
    type = sample(c("Always-Taker", "Never-Taker", "Complier", "Defier"),N, replace = TRUE, 
        prob = c(.1, 1 - unique(prob_comply), unique(prob_comply), 0))
)

## Los resultados potenciales no observados, Y (Z = 1) e Y (Z = 0) se relacionan con el resultado observado, Y, a través de la asignación de tratamiento y un efecto aditivo constante de tau.
  ## D se refiere a recibir una dosis de retroalimentación
  d_po <- declare_potential_outcomes(
      D ~ case_when(
          Z == 0 & type %in% c("Never-Taker", "Complier") ~ 0,
          Z == 1 & type %in% c("Never-Taker", "Defier") ~ 0,
          Z == 0 & type %in% c("Always-Taker", "Defier") ~ 1,
          Z == 1 & type %in% c("Always-Taker", "Complier") ~ 1
      )
  )

  y_po <- declare_potential_outcomes(
    Y ~ tau * sd(u) * D + u,
    assignment_variables = c("D", "Z")
  )
## La asignación de tratamiento para cualquier ciudad determinada es una proporción fija simple. Debe ser una tarea completa o de dibujar una urna, no una tarea simple o para tirar una moneda al aire.
## theassign <- declare_assignment (m = m)
the_assign<- declare_assignment(assignment_variable = "Z")

## declare_reveal es básicamente lo mismo que declare_potential_outcomes. Creo que tienen esto aquí para hacer frente a situaciones de falta de datos o incumplimiento.
# theveal <- declare_reveal (Y, Z)
d_reveal <- declare_reveal(... = D, assignment_variables = "Z")
y_reveal <- declare_reveal(Y, assignment_variables = c("D", "Z"))

base_design <- the_pop + the_assign +  d_po + y_po + d_reveal + y_reveal

dat0 <- draw_data(base_design)

 estimand_cace <- declare_estimand(
    CACE = mean((Y_D_1_Z_1 + Y_D_1_Z_0) / 2 -
      (Y_D_0_Z_1 + Y_D_0_Z_0) / 2),
    subset = type == "Complier"
  )
  estimand_ate <- declare_estimand(ATE = mean((Y_D_1_Z_1 + Y_D_1_Z_0) / 2 -
    (Y_D_0_Z_1 + Y_D_0_Z_0) / 2))
```

Algunos datos de ejemplo (donde conocemos todos los resultados potenciales):

```{r showdat0}
tempdat <- dat0[1:2,-1]
names(tempdat)[5] <- "pZ"
names(tempdat) <- gsub("_","",names(tempdat))
kableExtra::kable(tempdat, digits = 2)
```

## Cómo calcular el ITT y CACE / LATE II

La ITT y CACE (las partes)
```{r echo=TRUE}
itt_y <- difference_in_means(Y~Z,data=dat0)
itt_y
itt_d <- difference_in_means(D~Z,data=dat0)
itt_d
```

## Cómo calcular el ITT y CACE / LATE III

All together:^[works when $Z \rightarrow D$ is not weak see @imbens2005robust for a cautionary tale]

```{r echo=TRUE}
cace_est <- iv_robust(Y~D|Z,data=dat0)
cace_est
## Notice same as below:
coef(itt_y)[["Z"]]/coef(itt_d)[["Z"]]
```

## Resumen de diseños orientados al estímulo / cumplidor / dosis:

 - Analice como lo aleatorizó, incluso cuando no controla la dosis
 - El peligro del análisis por protocolo.
 
## References
