---
title: "Mesures"
author: "Mettre votre nom"
date: '`r format(Sys.time(), "%d %B, %Y")`'
bibliography: ../learningdays-book.bib
biblio-style: apalike
link-citations: yes
colorlinks: yes
header-includes: |
   \setbeamertemplate{footline}{\begin{beamercolorbox}{section in head/foot}
   \includegraphics[height=.5cm]{../Images/egap-logo.png} \hfill
   \insertframenumber/\inserttotalframenumber \end{beamercolorbox}}
   \usepackage{tikz}
   \usepackage{tikz-cd}
   \usepackage{textpos}
   \usepackage{booktabs,multirow,makecell}
output:
  beamer_presentation:
    keep_tex: yes
    toc: yes
  revealjs::revealjs_presentation:
    center: no
    highlight: pygments
    reveal_options:
      chalkboard:
        theme: whiteboard
        toggleNotesButton: no
      previewLinks: yes
      slideNumber: yes
    reveal_plugins:
    - notes
    - search
    - chalkboard
    self_contained: no
    smart: no
    theme: default
    transition: fade
---

# Un élément clé de votre design de recherche
## La mesure

- La mesure est une partie essentielle de votre design de recherche.

- La mesure découle de votre théorie, de la façon dont vous pensez que le monde fonctionne et dont vous pensez que votre traitement manipule ce monde.
  Autrement dit, la mesure est un exercice théorique autant que technique et logistique.

- Lorsque nous enregistrons un nombre, un mot ou une lettre dans un ensemble de données pour **représenter** quelque chose de plus ou moins abstrait dans le monde (comme "la stabilité financière", "la faim" ou "la capacité en mathématiques"), nous **mesurons**.

## Une mauvaise mesure est problématique

- Des problèmes de mesure peuvent vous amener à tirer des inférences (causales) incorrectes de votre étude (erreur systématique).

- Un bruit de mesure réduit la puissance statistique (erreur aléatoire).

## Collecte de données

- La collecte de données prend souvent une très grande partie du temps et des ressources financières disponibles dans le budget du projet.

- De nouvelles données peuvent être un résultat de recherche utile en soi et une base importante pour la recherche future. Les données sont un bien public !

# Concepts et mesures
## Du concept aux données/scores I

![Mesure du concept aux scores (ou données enregistrées). De @adcocoll:2001.](../Images/adcock_collier_2001_fig.pdf){#id .class width=75% height=75%}

## Du concept aux données/scores II

  - Quel exemple de concept, comme un résultat, aimeriez-vous changer avec un traitement expérimental ?

  - Comment sauriez-vous qu'une unité (comme une personne ou un village) affiche une "capacité" ou un "rang" élevé ou faible sur ce concept ?

  - Que pourriez-vous observer qui vous ferait sentir plus ou moins confiant que cette personne était plus affamée ou moins favorable à la violence que cette autre personne ?

  - À quelles critiques pourriez-vous faire face si vous disiez : « Je pense que cette unité diffère de cette autre unité sur mon résultat conceptuel ? »

## Validité de la mesure

- On parle ici de "**validité** de la mesure".

- Une mesure valide est une mesure pour laquelle nous pouvons argumenter de manière convaincante qu'elle représente ce que nous disons qu'elle représente, et elle ne représente pas d'autres aspects de l'unité.) (voir @shadish2002experimental pour en savoir plus sur la validité et la fiabilité de la mesure).

## Question I

- *"Un bateau qui peut faire quarante milles à l'heure en eau calme fait un voyage de cent milles le long d'un certain cours d'eau. Si ce voyage dure deux heures, combien de temps le retour prendra-t-il ?" (à partir de la SAT de 1926 aux USA)*

- Est-ce que cela mesure la "capacité en mathématiques" ? la "capacité verbale" ? ou la connaissance en navigation?

## Question II

Choisissez la paire de mots qui ressemble le plus à la paire du haut :

*Coureur : Marathon*

(a) envoyé : ambassade

(b) martyr : massacre

(c) rameur : régate

(d) cheval : écurie

La bonne réponse est : (c) rameur : régate. (à partir des années 1980 SAT aux USA)

- Est-ce que cela mesure la connaissance des sports universitaires ? Ou la "capacité verbale" ?

# Que mesurer
## Vous devez tout mesurer

    - Résultat pour toutes les unités de votre étude (pour chaque vague avec les données manquantes).

    - Traitement (assignation et observance).

    - Des indications que votre traitement est reçu et interprété comme vous l'attendez (contrôle de manipulation).

    - Indications de dommages possibles causés par vos recherches.

    - Covariables, y compris le contexte qui pourrait (a) affecter le fonctionnement de votre intervention ou (b) influencer la variabilité de votre résultat.

## Les indicateurs doivent être connectés aux théories et aux mécanismes

- Nous avons souvent plusieurs théories sur *comment* une intervention peut affecter un résultat (mécanismes différents).

- Mesurer des indicateurs qui sont *uniques* à chaque mécanisme et qui peuvent aider à *différencier* entre eux.

- Ces indicateurs peuvent inclure des résultats intermédiaires qui sont réalisés *avant* le résultat final.

- Ils peuvent inclure des résultats secondaires tels que

    - les résultats pour lesquels nous attendons des effets uniquement selon certaines théories.

    - les résultats placebo pour lesquels nous n'attendons aucun effet.

## Indicateurs

- Le cas idéal est la mesure directe du concept ou du phénomène d'intérêt sans erreur (rarement possible).

   - Une assignation de traitemenet sous votre contrôle est l'exception. Il est crucial de l'enregistrer.

- Nous ne sommes souvent en mesure de mesurer que des **indicateurs** liés mais pas entièrement déterminants pour le concept sous-jacent ou le phénomène d'intérêt.

    - Des réponses correctes à des problèmes spécifiques (indicateurs) pour l'aptitude mathématique sous-jacente (le phénomène réel).

    - Jours sans nourriture (indicateurs) de la faim (le phénomène réel).

## Sélectionnez des indicateurs valides

- Des personnes raisonnables peuvent être en désaccord sur la conceptualisation.
  Qu'entendons-nous vraiment par aptitude mathématique ou faim ?
  Qu'est-ce que nos scores pourraient dire d'autre sur les gens, villages, etc. en plus de ce que nous espérons représenter ?

- Sélectionnez des indicateurs étroitement liés à ce que nous **entendons** lorsque nous parlons du phénomène d'intérêt.

- Sélectionnez les indicateurs **valides**. Ex. La connaissance mathématique ne devrait pas également mesurer la connaissance en navigation.

## Sélectionnez des indicateurs fiables

- Sélectionnez des indicateurs qui sont **fiables**.

- Exemple : Un mètre doit toujours mesurer un mètre quelle que soit la température. Un mètre en caoutchouc peut produire des mesures **peu fiables** du concept abstrait de longueur, surtout s'il est utilisé par un enfant de 5 ans. Un laser peut produire des mesures plus fiables qu'un mètre en bois entre les mains d'un utilisateur expérimenté pour mètre en bois.

## Mesures multiples

  - Si vous avez _plusieurs indicateurs pour le même phénomène_, vous devrez déterminer comment agréger ces indicateurs.

       - La moyenne n'aura pas toujours de sens. Avez-vous des exemples ?

  - Avoir plusieurs indicateurs peut souvent améliorer la **fiabilité** de la mesure et peut-être renforcer les arguments en faveur de sa **validité**.

  - La combinaison d'un bâton en bois et d'un laser pourrait être idéale pour nous convaincre que nous avons mesuré la longueur d'une manière que nous comprenons comme **longueur** (plutôt que, disons, une température) _et_ que le score particulier ne dépend pas de manière cruciale du contexte de la mesure.

# Comment mesurer
## Outils de mesure et sources de données

- Après avoir déterminé quel concept mesurer et comment nous pourrions le connaître lorsque nous le voyons, nous devons déterminer **comment** le mesurer.

- Nous disposons de divers outils et sources :

    - Mesures d'enquête

    - Mesures comportementales

    - Données administratives (fiches fiscales, résultats des élections, etc.)

    - Images/télédétection

    - Texte (transcriptions de discours, journaux, etc.)

    - Capteurs électroniques, téléphones, autres appareils (appareils ménagers)

    - Autres

## Considérations dans le choix des outils et des sources
Différents outils impliquent différents compromis :

    - Validité (Le score capture-t-il le concept et uniquement le concept ?)

    - Fiabilité (Une procédure de notation utilisée deux fois donnerait-elle la même réponse ?)

    - Biais (erreur systématique)

    - Précision (erreur aléatoire)

    - Échantillon pour lequel vous pouvez faire des mesures

    - Timing des mesures

    - Coût

## Maintenir la symétrie entre les bras de traitement

- Vous devez maintenir la symétrie entre les groupes de traitement et de contrôle pendant que vous effectuez la mesure.

    - Le nombre de fois et pendant combien de temps vous interagissez avec les participants doit être le même dans tous les bras de traitement.

    - Les questions doivent être les mêmes.

    - Soyez particulièrement vigilant sur ces points pour les indicateurs utilisés pour les contrôles de manipulation.

- **La mesure ne doit pas être l'intervention expérimentale.** Nous voulons que la seule différence entre les bras de traitement soit l'intervention, pas la mesure.

# Erreur de mesure et ses conséquences
## Erreur de mesure I

- Nous voulons éviter/minimiser deux types d'erreur de mesure :

    - Erreur systématique (biais)

    - Erreur aléatoire (manque de précision)

## Erreur de mesure II

![Biais et précision](../Images/bullseye.png){#id1 .class width=60% height=60%}

[(Source : Précision et bias de mesure)](https://www.researchgate.net/figure/Bullseye-charts-representing-precision-and-bias-of-a-measurement-instrument-The-center-of_fig1_326134610)

## Exemples d'erreurs de mesure

- Erreur systématique

    - Une balance mal calibrée, donc tout le monde semble peser 2 kg de moins qu'ils ne le sont en réalité
    - Un journal alimentaire qui sous-évalue systématiquement les collations
    - Effet de demande
    - Effet Hawthorne

- Erreur aléatoire

    - Une main tremblante pour mesurer une distance

- Notez que ce sont des exemples de mesure **peu fiable**. Ils peuvent également être **invalides**, mais ce n'est pas obligatoire.

## Conséquences d'une mauvaise mesure du traitement

- En plus de générer une description incorrecte du niveau de certains phénomènes, l'erreur de mesure peut affecter nos inférences causales.

- Si la variable de traitement est binaire (une unité peut être en traitement ou en contrôle seulement), alors l'erreur de mesure est négativement corrélée avec la vraie variable. (Un 1 est mal codé comme 0, donc l'erreur est -1 ; un 0 est mal codé comme 1, donc l'erreur est 1.)

- Si vous utilisez la méthode des moindres carrés pour calculer les estimateurs d'effet moyen du traitement, ce type d'erreur conduit à des estimations plus petites de l'effet causal (coefficient sur la variable de traitement).

## Conséquences d'une erreur de mesure aléatoire

- Avec la méthode des moindres carrés, une erreur aléatoire plus importante dans la variable de résultat conduit à des estimations moins précises de l'effet causal (coefficient sur la variable de traitement).

- La réduction de l'erreur de mesure aléatoire dans le résultat peut augmenter la puissance statistique (car le résultat a moins de bruit non lié au traitement).

## Conséquences de l'erreur de mesure systématique I

- Si toutes les mesures sont décalées du même montant, comme -2kg pour tout le monde :

    - cela ne fait aucune différence lorsque les effets du traitement sont définis comme des différences dans les résultats potentiels,

    $\tau_i = Y_i(1)-Y_i(0)$, $\tilde{\tau_i} = (Y_i(1)-2)-(Y_i(0)-2)$,
    donc $\tau_i = \tilde{\tau_i}$

    - mais cela est problématique si l'effet du traitement est défini comme le rapport des résultats potentiels ($Y_i(1) > 0$ et $Y_i(0) > 0$).

    $\tau_i = Y_i(1)/Y_i(0)$,
    $\tilde{\tau_i} = (Y_i(1)-2)/(Y_i(0)-2)$, donc $\tau_i \neq \tilde{\tau_i}$ sauf quand $Y_i(1)=Y_i( 0)$.


- La distance entre $\tilde{\tau_i}$ et $\tau_i$ dépend de la taille de 2 (l'erreur) par rapport aux valeurs réelles $Y_i(0), Y_i(1)$.

- Remarque : les coefficients de régression logistique sont des ratios de résultats potentiels.

## Conséquences de l'erreur de mesure systématique II

- L'erreur de mesure peut être corrélée à la vraie valeur de $Y$.

- Par exemple, les personnes qui se livrent à un comportement désapprouvé, embarrassant ou illégal peuvent sous-déclarer ce comportement, tandis que celles qui ne le font pas le rapportent correctment. (Ceci est connu sous le nom de biais de désirabilité sociale.)
     - Cette sous-déclaration peut se produire avec les victimes de ce type de comportement, qui se blâment ou craignent des sanctions de ceux qui préfèrent ne pas connaître le comportement (par exemple, les victimes de violence entre partenaires intimes).

- Cela rend plus difficile la détection d'un effet d'une intervention visant à réduire ce comportement.

## Conséquences de l'erreur systématique de mesure III

- Une autre forme de biais de désirabilité sociale peut également conduire à corréler l'erreur de mesure avec le traitement.

- Par exemple, votre intervention pourrait viser à réduire les attitudes hostiles envers les membres d'autres groupes sociaux.
  Si les participants peuvent comprendre les objectifs de votre étude, ils peuvent (inconsciemment) essayer de plaire au chercheur en lui disant ce qu'il veut voir.
  Les personnes du groupe de traitement peuvent sous-estimer leur hostilité envers les autres groupes par rapport au groupe témoin.

- Cela rend difficile de savoir si la différence dans les résultats observés entre les groupes de traitement et de contrôle est due à l'intervention réduisant réellement l'hostilité ou à la connaissance du traitement modifiant le signalement de l'hostilité.

# Limiter l'erreur de mesure
## Quelques options pour limiter les erreurs de mesure

- L'auto-déclaration par un sujet (sur une enquête) est plus problématique que l'observation discrète du sujet ("dans la nature") par quelqu'un d'autre.

- Les mesures comportementales sont moins sujettes aux biais de désirabilité sociale.

- Les dossiers administratifs pour lesquels les fausses déclarations entraînent des sanctions légales pourraient être plus précis.

- Offrir plus de confidentialité afin que la notation puisse se faire sans observation du chercheur ou autres.

- Garder certaines hypothèses et objectifs de l'étude cachés aux participants à l'étude.

- Si vous ne pouvez pas contrôler l'erreur de mesure, étudiez-la --- déterminez s'il s'agit d'un problème et sa propension. Envisager des études pilotes axées sur la mesure.

## Example - administrative records

  - Attendance records for a meeting, instead of asking whether someone attended.

    - There may only be regular attendance records for meetings that are not of interest to your original target population.
    
    - You may need to plan ahead for data collection at a future meeting instead.

## Example - behavioral measures I

  - Ask subjects to induce effort like sign a petition, make a donation, or do some other task which has a small personal cost, instead of asking subjects whether they support a particular issue.

    - This may only capture subjects who care strongly about that issue.
    
    - Example: Pedro Vicente's work on vote-buying in Sao Tome and Principe uses surveys, administrative records, and whether respondents mailed a pre-paid postcard to measure outcomes. See [Brief 20: Is Vote Buying Effective?](https://egap.org/resource/brief-20-is-vote-buying-effective/)


## Example - behavioral measures II
  - Play "lab games" to measure cooperation or generosity towards out-groups, instead of asking subjects whether they would cooperate with others.

    - Scacco and Warren's study of prejudice and discrimination uses variants of dictator games.  See [Can Social Contact Reduce Prejudice and Discrimination? Evidence from a Field Experiment in Nigeria](https://www.cambridge.org/core/journals/american-political-science-review/article/can-social-contact-reduce-prejudice-and-discrimination-evidence-from-a-field-experiment-in-nigeria/230FAEB8E4E9E756BF8560FE62E2FBAC)

## Example - cover or privacy I
  - Provide "cover" so that respondents believe that their responses cannot be traced back to them.

      - Randomized response: chance determines whether the respondent should respond to a question truthfully or respond "yes" regardless of the truth.  The enumerator does not know which condition chance put the respondent in.

## Example - cover or privacy II
  - List experiments: give respondents a list of items or statements and ask how many many are true for them.  Respondents are randomized into seeing different lists, where one contains an additional sensitive item (e.g., "my husband beats me"). This allows the researcher to estimate the prevalence of a particular item.  Note that this approach reduces power for a given sample size.

  - Simple privacy: for questions such as vote choice, ask the respondent to fill out a mock ballot and place it in a locked box instead of responding directly to the enumerator.

## Example - blinding respondents to hypotheses

  - See Scacco and Warren's study of social contact theory in Kaduna, Nigeria, where participants were recruiting into a computer skills program, not one advertised as a program to reduce prejudice and discrimination.
  

## How much error is too much?

- Reducing measurement error is important, but can be quite costly.  So how much do you need to do?

- Depends on the scale and your goals.

   - Compare size of errors to the size of the treatment effect.  Changing attitudes is difficult.  Social desirability bias may be large compared with small treatment effects on attitudes.
   
   - Compare size of errors to the possible range of that outcome.  Being one cent off on your bank balance does not appreciably affect our measure of your overall wealth.

## General advice for measurement I

- Start with standard practice for your indicators --indicators that the  community of researchers has agreed represent the concept of interest.
  
    - These will have been road-tested for you and comparability of measures across  research studies and sites is a virtue.

- But be careful to consider whether the standard indicators make sense.  

    - For example, how one measures income might differ between rich and poor areas.
    
    - Similarly, how one measures political attitudes might differ in more or less democratic regimes.

## General advice for measurement II

 - Recall that the boating-related measures of math and verbal ability were   standard practice in the 1920s and 1980s in the USA. Remember that you are   measuring social constructs and thus must pay attention, as much as you can,   to what prior partially or unexamined beliefs you and the community of   researchers bring to the study (for some more vivid examples of this issue,   see @gould1996mismeasure).

- Connect with other researchers in your subject area.

- Focus on finer measurement in the range of the variable where you expect change.

## Resources for survey research and survey items

- Major data archives are searchable by topic.  One major archive is ICPSR:

\url{https://www.icpsr.umich.edu/web/pages/ICPSR/}

- Pew Research Center on Questionnaire Design

\url{https://www.pewresearch.org/methods/u-s-survey-research/questionnaire-design/}

- Tools4Dev on Writing Questions

\url{http://www.tools4dev.org/resources/how-to-write-awesome-survey-questions-part-1/}

- University libraries will often have guides to data resources:

\url{https://guides.libraries.emory.edu/c.php?g=944707&p=6810109}

## Réferences

[10 Things to Know About Measurement in Experiments](https://egap.org/resource/10-things-to-know-about-measurement-in-experiments/)
